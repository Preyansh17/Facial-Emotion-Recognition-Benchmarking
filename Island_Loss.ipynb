{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3GOAxj32hRF",
        "outputId": "b98536ad-fda8-4a13-ad79-118648a4b928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':6, 'Sad':4, 'Surprise':5}\n",
        "\n",
        "def resize_to_224(x):\n",
        "    train = []\n",
        "    mat = np.reshape(x[:,:,0], (256, 256))\n",
        "    src = cv2.resize(mat, dsize=(200,200))\n",
        "    src = src.astype(np.float16)\n",
        "    train.append(src)\n",
        "    mat = np.reshape(x[:,:,1], (256, 256))\n",
        "    src = cv2.resize(mat, dsize=(200,200))\n",
        "    src = src.astype(np.float16)\n",
        "    train.append(src)\n",
        "    mat = np.reshape(x[:,:,2], (256, 256))\n",
        "    src = cv2.resize(mat, dsize=(200,200))\n",
        "    src = src.astype(np.float16)\n",
        "    train.append(src)\n",
        "    return train\n",
        "\n",
        "\n",
        "def getData2(balance_ones=True):\n",
        "\n",
        "    src = \"/content/drive/MyDrive/DATASET/online split\"\n",
        "    Yte = []\n",
        "    Xte = []\n",
        "    Xtr = []\n",
        "    Ytr = []\n",
        "    Xval = []\n",
        "    Yval = []\n",
        "\n",
        "    emotions  =  os.listdir(os.path.join(src,\"train\"))\n",
        "    for emotion in emotions:\n",
        "      print(emotion)\n",
        "      dir = os.listdir(os.path.join(src,\"train\",emotion))\n",
        "      for image in dir:\n",
        "        img = Image.open(\"/content/drive/MyDrive/DATASET/online split/train\"+\"/\"+emotion+\"/\"+image)\n",
        "        data = asarray(img)\n",
        "        data = data/255.0\n",
        "        try:\n",
        "          train = resize_to_224(data)\n",
        "        except:\n",
        "          continue\n",
        "        Xtr.append(train)\n",
        "        Ytr.append(emotion_to_index[emotion])\n",
        "    \n",
        "    # src = \"/content/drive/MyDrive/DATASET/human_split\"\n",
        "    emotions  =  os.listdir(os.path.join(src,\"test\"))\n",
        "    for emotion in emotions:\n",
        "      print(emotion)\n",
        "      dir = os.listdir(os.path.join(src,\"test\",emotion))\n",
        "      for image in dir:\n",
        "        img = Image.open(\"/content/drive/MyDrive/DATASET/online split/test\"+\"/\"+emotion+\"/\"+image)\n",
        "        data = asarray(img)\n",
        "        data = data/255.0\n",
        "        try:\n",
        "          train = resize_to_224(data)\n",
        "        except:\n",
        "          continue\n",
        "        Xte.append(train)\n",
        "        Yte.append(emotion_to_index[emotion])\n",
        "\n",
        "    emotions  =  os.listdir(os.path.join(src,\"val\"))\n",
        "    for emotion in emotions:\n",
        "      print(emotion)\n",
        "      dir = os.listdir(os.path.join(src,\"val\",emotion))\n",
        "      for image in dir:\n",
        "        img = Image.open(\"/content/drive/MyDrive/DATASET/online split/val\"+\"/\"+emotion+\"/\"+image)\n",
        "        data = asarray(img)\n",
        "        data = data/255.0\n",
        "        try:\n",
        "          train = resize_to_224(data)\n",
        "        except:\n",
        "          continue\n",
        "        Xval.append(train)\n",
        "        Yval.append(emotion_to_index[emotion])\n",
        "\n",
        "\n",
        "\n",
        "    Xte, Yte = np.array(Xte, dtype=np.float16), np.array(Yte)\n",
        "    Xtr, Ytr = np.array(Xtr, dtype=np.float16), np.array(Ytr)\n",
        "    Xval, Yval = np.array(Xval, dtype=np.float16), np.array(Yval)\n",
        "\n",
        "    return Xtr, Ytr, Xte, Yte,Xval, Yval\n",
        "\n",
        "def Reverse(data):\n",
        "    data = data * -1\n",
        "    data = data + 1\n",
        "    return data"
      ],
      "metadata": {
        "id": "fYc28B7FITN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cBcMjoPAeT92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Input, Dense, MaxPooling2D, Flatten, Activation, Embedding, Lambda\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "from keras import backend\n",
        "from keras import losses\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "backend.set_image_data_format('channels_first')\n",
        "\n",
        "label_size = 7\n",
        "\n",
        "class IslandLossLayer(Layer):\n",
        "    def __init__(self, alpha=0.5,lambda_2=0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.first = True\n",
        "        self.alpha = alpha\n",
        "        self.lambda_2 = lambda_2\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.centers = self.add_weight(name='centers', shape=(7,1024), initializer='uniform', trainable=False)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def L2Norm(ts):\n",
        "        return K.sqrt(K.sum(ts ** 2, keepdims=True))\n",
        "\n",
        "    def pairwise_distance(self, pair):\n",
        "        fea_k = tf.reshape(self.centers[pair[0]], (1,1024))\n",
        "        fea_j = tf.reshape(self.centers[pair[1]], (1,1024))\n",
        "\n",
        "        NormK = tf.norm(fea_k, ord=2, axis=1, keepdims=False)\n",
        "        NormJ = tf.norm(fea_j, ord=2, axis=1, keepdims=False)\n",
        "        # 1x1\n",
        "        return K.dot(fea_k, K.transpose(fea_j)) / (NormK * NormJ) + 1\n",
        "\n",
        "\n",
        "    def pairwise_diff(self, pair):\n",
        "        Ck = tf.reshape(self.centers[pair[0]], (1,1024))\n",
        "        Cj = tf.reshape(self.centers[pair[1]], (1,1024))\n",
        "\n",
        "        NormK = tf.norm(Ck, ord=2, axis=1, keepdims=False)\n",
        "        NormJ = tf.norm(Cj, ord=2, axis=1, keepdims=False)\n",
        "\n",
        "        A = Ck / (NormK * NormJ)\n",
        "        B = (K.dot(Ck, K.transpose(Cj)) / (NormK * (NormJ ** 3))) * Cj\n",
        "\n",
        "        # 1 x 1024\n",
        "        T = A - B\n",
        "        return T\n",
        "\n",
        "    # x[0] is N*1024 , X[1] is N*7 one hot,\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        index = np.arange(label_size)\n",
        "        combination = itertools.permutations(index, 2)\n",
        "\n",
        "        Centers = K.dot(x[1], self.centers)\n",
        "        delta_centers = K.dot(K.transpose(x[1]), Centers - x[0])\n",
        "        center_counts = K.sum(K.transpose(x[1]), axis=1, keepdims=True) + 1\n",
        "        delta_centers /= center_counts\n",
        "\n",
        "        # # 7 x N\n",
        "        # mask_labels = K.transpose(Reverse(x[1]))\n",
        "        # labels_norm = tf.norm(x[1], ord=2, axis=1, keep_dims=True)\n",
        "        # A = x[1] / (labels_norm * labels_norm) # Nx7\n",
        "        # B = K.dot(K.dot(x[1], K.transpose(x[1])) / (labels_norm * (labels_norm ** 3)), x[1]) # K.dot( NxN, Nx7 ) = Nx7\n",
        "        # add_centers_distance = self.lambda_2 / (label_size-1) * K.dot(K.dot(mask_labels, A - B), self.centers) # 7x1024\n",
        "        # new_centers = self.centers - self.alpha * delta_centers + add_centers_distance\n",
        "\n",
        "\n",
        "        # j = 0,1,2,3,4,...label type\n",
        "        T = []\n",
        "        for j in range(x[1].shape[1]):\n",
        "            Sum = tf.zeros(shape=(1, 1024))\n",
        "            for pair in combination:\n",
        "                if pair[0] == j:\n",
        "                    # we need this pair\n",
        "                    Sum += self.pairwise_diff(pair)\n",
        "            T.append(Sum)\n",
        "\n",
        "        add_centers_distance = tf.reshape(tf.stack(T,1), (-1,1024))\n",
        "        add_centers_distance = (self.lambda_2 / (label_size-1)) * add_centers_distance\n",
        "        new_centers = self.centers - self.alpha * delta_centers + add_centers_distance\n",
        "        self.add_update((self.centers, new_centers), x)\n",
        "\n",
        "\n",
        "        # Center Loss calculate\n",
        "        self.result = x[0] - K.dot(x[1], self.centers)\n",
        "        self.result = 0.5 * K.sum(self.result**2, axis=1, keepdims=True)\n",
        "\n",
        "        # Island Loss calculate\n",
        "        pairDistance = 0\n",
        "        for pair in combination:\n",
        "            pairDistance += self.pairwise_distance(pair)\n",
        "        pairDistance *= self.lambda_2\n",
        "        self.result += pairDistance\n",
        "\n",
        "\n",
        "        # N x 1\n",
        "        return self.result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return K.int_shape(self.result)\n",
        "\n",
        "\n",
        "def baseModel(alpha, img, labels):\n",
        "\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(img)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
        "\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=img, outputs=x, name='vggface_vgg16')  # load weights\n",
        "    weights_path = '/content/drive/MyDrive/DATASET/models/rcmalli_vggface_tf_notop_vgg16.h5'\n",
        "    model.load_weights(weights_path)\n",
        "\n",
        "    for layer in model.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    base_model_output = model.output\n",
        "    x = Flatten(name='flatten_final_model')(base_model_output)\n",
        "    x = Dense(1024, name='fc_final_1')(x)\n",
        "    x = Activation('relu', name='ss')(x)\n",
        "    x = Dense(1024, name='fc_final_2')(x)\n",
        "    x = Activation('relu', name='side_out')(x)\n",
        "\n",
        "    main = Dense(7, activation='softmax', name='main_out')(x)\n",
        "    side = IslandLossLayer(alpha=alpha, lambda_2=0.003, name='Ialnslosslayer')([x, labels])\n",
        "\n",
        "    return main, side\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generateModel2(initial_learning_rate = 1e-3, lambda_c = 0.003, alpha = 0.5):\n",
        "    main_input = Input(shape=(3, 200,200)) \n",
        "    aux_input = Input(shape=(7,))\n",
        "\n",
        "    Final_output, Side_output = baseModel(alpha, main_input, aux_input)\n",
        "    model = Model(inputs=[main_input, aux_input], outputs=[Final_output, Side_output])\n",
        "    model.compile(optimizer=SGD(initial_learning_rate, momentum=0.9),\n",
        "                  loss=[losses.categorical_crossentropy, lambda y_true, y_pred: y_pred],\n",
        "                  loss_weights=[1, lambda_c],\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "D5_VsttddM1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99LudCtQH50D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d019cc24-ae9e-4780-b586-28fc2e79b3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fear\n",
            "Neutral\n",
            "Happy\n",
            "Angry\n",
            "Disgust\n",
            "Sad\n",
            "Surprise\n",
            "Fear\n",
            "Neutral\n",
            "Happy\n",
            "Angry\n",
            "Disgust\n",
            "Sad\n",
            "Surprise\n",
            "Disgust\n",
            "Fear\n",
            "Happy\n",
            "Neutral\n",
            "Sad\n",
            "Surprise\n",
            "Angry\n",
            "(1958, 3, 200, 200)\n",
            "(1958,)\n",
            "Consumption time 15.498628377914429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - ETA: 0s - loss: 2.1246 - main_out_loss: 1.9313 - Ialnslosslayer_loss: 0.9664 - main_out_accuracy: 0.2273 - Ialnslosslayer_accuracy: 0.0199"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 6s 174ms/step - loss: 2.1246 - main_out_loss: 1.9313 - Ialnslosslayer_loss: 0.9664 - main_out_accuracy: 0.2273 - Ialnslosslayer_accuracy: 0.0199 - val_loss: 2.0567 - val_main_out_loss: 1.9253 - val_Ialnslosslayer_loss: 0.6569 - val_main_out_accuracy: 0.2460 - val_Ialnslosslayer_accuracy: 0.0444\n",
            "Epoch 2/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 2.0379 - main_out_loss: 1.9182 - Ialnslosslayer_loss: 0.5985 - main_out_accuracy: 0.2380 - Ialnslosslayer_accuracy: 0.1318 - val_loss: 2.0301 - val_main_out_loss: 1.9169 - val_Ialnslosslayer_loss: 0.5659 - val_main_out_accuracy: 0.2097 - val_Ialnslosslayer_accuracy: 0.1573\n",
            "Epoch 3/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 2.0188 - main_out_loss: 1.9086 - Ialnslosslayer_loss: 0.5512 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.2385 - val_loss: 2.0179 - val_main_out_loss: 1.9093 - val_Ialnslosslayer_loss: 0.5429 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2339\n",
            "Epoch 4/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 2.0067 - main_out_loss: 1.8994 - Ialnslosslayer_loss: 0.5367 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.2962 - val_loss: 2.0090 - val_main_out_loss: 1.9021 - val_Ialnslosslayer_loss: 0.5348 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2702\n",
            "Epoch 5/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.9966 - main_out_loss: 1.8902 - Ialnslosslayer_loss: 0.5324 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.3212 - val_loss: 2.0011 - val_main_out_loss: 1.8942 - val_Ialnslosslayer_loss: 0.5342 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2903\n",
            "Epoch 6/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.9871 - main_out_loss: 1.8802 - Ialnslosslayer_loss: 0.5342 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.3141 - val_loss: 1.9931 - val_main_out_loss: 1.8854 - val_Ialnslosslayer_loss: 0.5389 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2823\n",
            "Epoch 7/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.9772 - main_out_loss: 1.8690 - Ialnslosslayer_loss: 0.5413 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.2952 - val_loss: 1.9847 - val_main_out_loss: 1.8751 - val_Ialnslosslayer_loss: 0.5482 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2460\n",
            "Epoch 8/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.9663 - main_out_loss: 1.8555 - Ialnslosslayer_loss: 0.5539 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.2661 - val_loss: 1.9746 - val_main_out_loss: 1.8619 - val_Ialnslosslayer_loss: 0.5634 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.2177\n",
            "Epoch 9/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.9533 - main_out_loss: 1.8387 - Ialnslosslayer_loss: 0.5734 - main_out_accuracy: 0.2186 - Ialnslosslayer_accuracy: 0.2365 - val_loss: 1.9622 - val_main_out_loss: 1.8449 - val_Ialnslosslayer_loss: 0.5862 - val_main_out_accuracy: 0.2137 - val_Ialnslosslayer_accuracy: 0.1774\n",
            "Epoch 10/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.9375 - main_out_loss: 1.8167 - Ialnslosslayer_loss: 0.6039 - main_out_accuracy: 0.2191 - Ialnslosslayer_accuracy: 0.2068 - val_loss: 1.9455 - val_main_out_loss: 1.8205 - val_Ialnslosslayer_loss: 0.6247 - val_main_out_accuracy: 0.2177 - val_Ialnslosslayer_accuracy: 0.1452\n",
            "Epoch 11/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.9170 - main_out_loss: 1.7888 - Ialnslosslayer_loss: 0.6409 - main_out_accuracy: 0.2334 - Ialnslosslayer_accuracy: 0.1782 - val_loss: 1.9254 - val_main_out_loss: 1.7909 - val_Ialnslosslayer_loss: 0.6725 - val_main_out_accuracy: 0.2298 - val_Ialnslosslayer_accuracy: 0.1210\n",
            "Epoch 12/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.8940 - main_out_loss: 1.7522 - Ialnslosslayer_loss: 0.7090 - main_out_accuracy: 0.2681 - Ialnslosslayer_accuracy: 0.1364 - val_loss: 1.9021 - val_main_out_loss: 1.7558 - val_Ialnslosslayer_loss: 0.7312 - val_main_out_accuracy: 0.2702 - val_Ialnslosslayer_accuracy: 0.1089\n",
            "Epoch 13/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.8691 - main_out_loss: 1.7161 - Ialnslosslayer_loss: 0.7647 - main_out_accuracy: 0.3468 - Ialnslosslayer_accuracy: 0.1205 - val_loss: 1.8803 - val_main_out_loss: 1.7243 - val_Ialnslosslayer_loss: 0.7802 - val_main_out_accuracy: 0.3548 - val_Ialnslosslayer_accuracy: 0.0927\n",
            "Epoch 14/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.8446 - main_out_loss: 1.6804 - Ialnslosslayer_loss: 0.8211 - main_out_accuracy: 0.4311 - Ialnslosslayer_accuracy: 0.0996 - val_loss: 1.8598 - val_main_out_loss: 1.6895 - val_Ialnslosslayer_loss: 0.8517 - val_main_out_accuracy: 0.4073 - val_Ialnslosslayer_accuracy: 0.0645\n",
            "Epoch 15/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.8208 - main_out_loss: 1.6468 - Ialnslosslayer_loss: 0.8703 - main_out_accuracy: 0.4867 - Ialnslosslayer_accuracy: 0.0756 - val_loss: 1.8410 - val_main_out_loss: 1.6626 - val_Ialnslosslayer_loss: 0.8918 - val_main_out_accuracy: 0.4597 - val_Ialnslosslayer_accuracy: 0.0524\n",
            "Epoch 16/75\n",
            "31/31 [==============================] - 5s 154ms/step - loss: 1.7973 - main_out_loss: 1.6141 - Ialnslosslayer_loss: 0.9159 - main_out_accuracy: 0.5291 - Ialnslosslayer_accuracy: 0.0644 - val_loss: 1.8230 - val_main_out_loss: 1.6366 - val_Ialnslosslayer_loss: 0.9319 - val_main_out_accuracy: 0.4919 - val_Ialnslosslayer_accuracy: 0.0444\n",
            "Epoch 17/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.7738 - main_out_loss: 1.5814 - Ialnslosslayer_loss: 0.9618 - main_out_accuracy: 0.5480 - Ialnslosslayer_accuracy: 0.0506 - val_loss: 1.8053 - val_main_out_loss: 1.6041 - val_Ialnslosslayer_loss: 1.0056 - val_main_out_accuracy: 0.5040 - val_Ialnslosslayer_accuracy: 0.0242\n",
            "Epoch 18/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.7504 - main_out_loss: 1.5471 - Ialnslosslayer_loss: 1.0163 - main_out_accuracy: 0.5741 - Ialnslosslayer_accuracy: 0.0414 - val_loss: 1.7875 - val_main_out_loss: 1.5879 - val_Ialnslosslayer_loss: 0.9983 - val_main_out_accuracy: 0.5323 - val_Ialnslosslayer_accuracy: 0.0242\n",
            "Epoch 19/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.7277 - main_out_loss: 1.5191 - Ialnslosslayer_loss: 1.0433 - main_out_accuracy: 0.5981 - Ialnslosslayer_accuracy: 0.0363 - val_loss: 1.7700 - val_main_out_loss: 1.5625 - val_Ialnslosslayer_loss: 1.0374 - val_main_out_accuracy: 0.5484 - val_Ialnslosslayer_accuracy: 0.0242\n",
            "Epoch 20/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.7042 - main_out_loss: 1.4859 - Ialnslosslayer_loss: 1.0917 - main_out_accuracy: 0.6185 - Ialnslosslayer_accuracy: 0.0317 - val_loss: 1.7524 - val_main_out_loss: 1.5298 - val_Ialnslosslayer_loss: 1.1131 - val_main_out_accuracy: 0.5524 - val_Ialnslosslayer_accuracy: 0.0242\n",
            "Epoch 21/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.6814 - main_out_loss: 1.4537 - Ialnslosslayer_loss: 1.1385 - main_out_accuracy: 0.6369 - Ialnslosslayer_accuracy: 0.0271 - val_loss: 1.7355 - val_main_out_loss: 1.5040 - val_Ialnslosslayer_loss: 1.1576 - val_main_out_accuracy: 0.5524 - val_Ialnslosslayer_accuracy: 0.0202\n",
            "Epoch 22/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.6586 - main_out_loss: 1.4213 - Ialnslosslayer_loss: 1.1868 - main_out_accuracy: 0.6491 - Ialnslosslayer_accuracy: 0.0250 - val_loss: 1.7190 - val_main_out_loss: 1.4821 - val_Ialnslosslayer_loss: 1.1845 - val_main_out_accuracy: 0.5726 - val_Ialnslosslayer_accuracy: 0.0202\n",
            "Epoch 23/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.6362 - main_out_loss: 1.3938 - Ialnslosslayer_loss: 1.2120 - main_out_accuracy: 0.6619 - Ialnslosslayer_accuracy: 0.0225 - val_loss: 1.7024 - val_main_out_loss: 1.4655 - val_Ialnslosslayer_loss: 1.1843 - val_main_out_accuracy: 0.5847 - val_Ialnslosslayer_accuracy: 0.0202\n",
            "Epoch 24/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.6141 - main_out_loss: 1.3633 - Ialnslosslayer_loss: 1.2542 - main_out_accuracy: 0.6762 - Ialnslosslayer_accuracy: 0.0189 - val_loss: 1.6860 - val_main_out_loss: 1.4412 - val_Ialnslosslayer_loss: 1.2239 - val_main_out_accuracy: 0.6008 - val_Ialnslosslayer_accuracy: 0.0161\n",
            "Epoch 25/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.5920 - main_out_loss: 1.3408 - Ialnslosslayer_loss: 1.2560 - main_out_accuracy: 0.6844 - Ialnslosslayer_accuracy: 0.0174 - val_loss: 1.6706 - val_main_out_loss: 1.4183 - val_Ialnslosslayer_loss: 1.2615 - val_main_out_accuracy: 0.6089 - val_Ialnslosslayer_accuracy: 0.0161\n",
            "Epoch 26/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.5703 - main_out_loss: 1.3070 - Ialnslosslayer_loss: 1.3165 - main_out_accuracy: 0.7012 - Ialnslosslayer_accuracy: 0.0143 - val_loss: 1.6546 - val_main_out_loss: 1.3962 - val_Ialnslosslayer_loss: 1.2918 - val_main_out_accuracy: 0.6048 - val_Ialnslosslayer_accuracy: 0.0161\n",
            "Epoch 27/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.5482 - main_out_loss: 1.2822 - Ialnslosslayer_loss: 1.3301 - main_out_accuracy: 0.7043 - Ialnslosslayer_accuracy: 0.0138 - val_loss: 1.6398 - val_main_out_loss: 1.3781 - val_Ialnslosslayer_loss: 1.3084 - val_main_out_accuracy: 0.6169 - val_Ialnslosslayer_accuracy: 0.0121\n",
            "Epoch 28/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.5263 - main_out_loss: 1.2534 - Ialnslosslayer_loss: 1.3645 - main_out_accuracy: 0.7191 - Ialnslosslayer_accuracy: 0.0123 - val_loss: 1.6235 - val_main_out_loss: 1.3578 - val_Ialnslosslayer_loss: 1.3283 - val_main_out_accuracy: 0.6250 - val_Ialnslosslayer_accuracy: 0.0121\n",
            "Epoch 29/75\n",
            "31/31 [==============================] - 5s 154ms/step - loss: 1.5048 - main_out_loss: 1.2296 - Ialnslosslayer_loss: 1.3759 - main_out_accuracy: 0.7268 - Ialnslosslayer_accuracy: 0.0117 - val_loss: 1.6082 - val_main_out_loss: 1.3415 - val_Ialnslosslayer_loss: 1.3334 - val_main_out_accuracy: 0.6371 - val_Ialnslosslayer_accuracy: 0.0121\n",
            "Epoch 30/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.4838 - main_out_loss: 1.1991 - Ialnslosslayer_loss: 1.4237 - main_out_accuracy: 0.7324 - Ialnslosslayer_accuracy: 0.0112 - val_loss: 1.5957 - val_main_out_loss: 1.3213 - val_Ialnslosslayer_loss: 1.3717 - val_main_out_accuracy: 0.6250 - val_Ialnslosslayer_accuracy: 0.0081\n",
            "Epoch 31/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.4621 - main_out_loss: 1.1772 - Ialnslosslayer_loss: 1.4245 - main_out_accuracy: 0.7446 - Ialnslosslayer_accuracy: 0.0097 - val_loss: 1.5792 - val_main_out_loss: 1.3012 - val_Ialnslosslayer_loss: 1.3901 - val_main_out_accuracy: 0.6411 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 32/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.4407 - main_out_loss: 1.1491 - Ialnslosslayer_loss: 1.4582 - main_out_accuracy: 0.7513 - Ialnslosslayer_accuracy: 0.0092 - val_loss: 1.5642 - val_main_out_loss: 1.2931 - val_Ialnslosslayer_loss: 1.3553 - val_main_out_accuracy: 0.6411 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 33/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.4190 - main_out_loss: 1.1242 - Ialnslosslayer_loss: 1.4739 - main_out_accuracy: 0.7640 - Ialnslosslayer_accuracy: 0.0072 - val_loss: 1.5512 - val_main_out_loss: 1.2678 - val_Ialnslosslayer_loss: 1.4170 - val_main_out_accuracy: 0.6492 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 34/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.3982 - main_out_loss: 1.1036 - Ialnslosslayer_loss: 1.4727 - main_out_accuracy: 0.7717 - Ialnslosslayer_accuracy: 0.0072 - val_loss: 1.5396 - val_main_out_loss: 1.2482 - val_Ialnslosslayer_loss: 1.4568 - val_main_out_accuracy: 0.6331 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 35/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.3782 - main_out_loss: 1.0741 - Ialnslosslayer_loss: 1.5204 - main_out_accuracy: 0.7783 - Ialnslosslayer_accuracy: 0.0056 - val_loss: 1.5237 - val_main_out_loss: 1.2343 - val_Ialnslosslayer_loss: 1.4473 - val_main_out_accuracy: 0.6452 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 36/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.3574 - main_out_loss: 1.0537 - Ialnslosslayer_loss: 1.5185 - main_out_accuracy: 0.7886 - Ialnslosslayer_accuracy: 0.0051 - val_loss: 1.5137 - val_main_out_loss: 1.2237 - val_Ialnslosslayer_loss: 1.4501 - val_main_out_accuracy: 0.6532 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 37/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.3356 - main_out_loss: 1.0264 - Ialnslosslayer_loss: 1.5462 - main_out_accuracy: 0.7942 - Ialnslosslayer_accuracy: 0.0036 - val_loss: 1.4980 - val_main_out_loss: 1.2096 - val_Ialnslosslayer_loss: 1.4417 - val_main_out_accuracy: 0.6613 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 38/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.3148 - main_out_loss: 1.0017 - Ialnslosslayer_loss: 1.5656 - main_out_accuracy: 0.7998 - Ialnslosslayer_accuracy: 0.0036 - val_loss: 1.4861 - val_main_out_loss: 1.1999 - val_Ialnslosslayer_loss: 1.4307 - val_main_out_accuracy: 0.6613 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 39/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.2940 - main_out_loss: 0.9819 - Ialnslosslayer_loss: 1.5607 - main_out_accuracy: 0.8105 - Ialnslosslayer_accuracy: 0.0036 - val_loss: 1.4738 - val_main_out_loss: 1.1729 - val_Ialnslosslayer_loss: 1.5044 - val_main_out_accuracy: 0.6694 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 40/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.2735 - main_out_loss: 0.9585 - Ialnslosslayer_loss: 1.5751 - main_out_accuracy: 0.8156 - Ialnslosslayer_accuracy: 0.0031 - val_loss: 1.4636 - val_main_out_loss: 1.1607 - val_Ialnslosslayer_loss: 1.5143 - val_main_out_accuracy: 0.6573 - val_Ialnslosslayer_accuracy: 0.0040\n",
            "Epoch 41/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.2546 - main_out_loss: 0.9339 - Ialnslosslayer_loss: 1.6039 - main_out_accuracy: 0.8197 - Ialnslosslayer_accuracy: 0.0026 - val_loss: 1.4490 - val_main_out_loss: 1.1494 - val_Ialnslosslayer_loss: 1.4979 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 42/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.2341 - main_out_loss: 0.9145 - Ialnslosslayer_loss: 1.5981 - main_out_accuracy: 0.8248 - Ialnslosslayer_accuracy: 0.0020 - val_loss: 1.4394 - val_main_out_loss: 1.1382 - val_Ialnslosslayer_loss: 1.5058 - val_main_out_accuracy: 0.6855 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 43/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.2139 - main_out_loss: 0.8872 - Ialnslosslayer_loss: 1.6335 - main_out_accuracy: 0.8320 - Ialnslosslayer_accuracy: 0.0020 - val_loss: 1.4328 - val_main_out_loss: 1.1335 - val_Ialnslosslayer_loss: 1.4965 - val_main_out_accuracy: 0.6734 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 44/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.1939 - main_out_loss: 0.8696 - Ialnslosslayer_loss: 1.6215 - main_out_accuracy: 0.8355 - Ialnslosslayer_accuracy: 0.0020 - val_loss: 1.4201 - val_main_out_loss: 1.1239 - val_Ialnslosslayer_loss: 1.4811 - val_main_out_accuracy: 0.7097 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 45/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.1741 - main_out_loss: 0.8451 - Ialnslosslayer_loss: 1.6451 - main_out_accuracy: 0.8478 - Ialnslosslayer_accuracy: 0.0020 - val_loss: 1.4074 - val_main_out_loss: 1.1046 - val_Ialnslosslayer_loss: 1.5141 - val_main_out_accuracy: 0.6855 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 46/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.1548 - main_out_loss: 0.8258 - Ialnslosslayer_loss: 1.6447 - main_out_accuracy: 0.8524 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3977 - val_main_out_loss: 1.0961 - val_Ialnslosslayer_loss: 1.5081 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 47/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.1359 - main_out_loss: 0.8067 - Ialnslosslayer_loss: 1.6458 - main_out_accuracy: 0.8570 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3872 - val_main_out_loss: 1.0816 - val_Ialnslosslayer_loss: 1.5280 - val_main_out_accuracy: 0.7177 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 48/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.1151 - main_out_loss: 0.7814 - Ialnslosslayer_loss: 1.6685 - main_out_accuracy: 0.8631 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3816 - val_main_out_loss: 1.0704 - val_Ialnslosslayer_loss: 1.5561 - val_main_out_accuracy: 0.6935 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 49/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.0969 - main_out_loss: 0.7634 - Ialnslosslayer_loss: 1.6675 - main_out_accuracy: 0.8677 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3742 - val_main_out_loss: 1.0575 - val_Ialnslosslayer_loss: 1.5833 - val_main_out_accuracy: 0.6855 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 50/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 1.0784 - main_out_loss: 0.7425 - Ialnslosslayer_loss: 1.6791 - main_out_accuracy: 0.8723 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3679 - val_main_out_loss: 1.0555 - val_Ialnslosslayer_loss: 1.5619 - val_main_out_accuracy: 0.6855 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 51/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.0607 - main_out_loss: 0.7203 - Ialnslosslayer_loss: 1.7024 - main_out_accuracy: 0.8718 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3553 - val_main_out_loss: 1.0535 - val_Ialnslosslayer_loss: 1.5092 - val_main_out_accuracy: 0.7177 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 52/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.0426 - main_out_loss: 0.7072 - Ialnslosslayer_loss: 1.6770 - main_out_accuracy: 0.8825 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3448 - val_main_out_loss: 1.0360 - val_Ialnslosslayer_loss: 1.5439 - val_main_out_accuracy: 0.7097 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 53/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.0235 - main_out_loss: 0.6849 - Ialnslosslayer_loss: 1.6931 - main_out_accuracy: 0.8846 - Ialnslosslayer_accuracy: 0.0015 - val_loss: 1.3366 - val_main_out_loss: 1.0292 - val_Ialnslosslayer_loss: 1.5367 - val_main_out_accuracy: 0.7056 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 54/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 1.0049 - main_out_loss: 0.6654 - Ialnslosslayer_loss: 1.6978 - main_out_accuracy: 0.8912 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3281 - val_main_out_loss: 1.0195 - val_Ialnslosslayer_loss: 1.5430 - val_main_out_accuracy: 0.7137 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 55/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.9870 - main_out_loss: 0.6482 - Ialnslosslayer_loss: 1.6939 - main_out_accuracy: 0.8968 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3260 - val_main_out_loss: 1.0109 - val_Ialnslosslayer_loss: 1.5754 - val_main_out_accuracy: 0.7016 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 56/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.9693 - main_out_loss: 0.6256 - Ialnslosslayer_loss: 1.7186 - main_out_accuracy: 0.8979 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3165 - val_main_out_loss: 1.0176 - val_Ialnslosslayer_loss: 1.4945 - val_main_out_accuracy: 0.7137 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 57/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.9534 - main_out_loss: 0.6137 - Ialnslosslayer_loss: 1.6984 - main_out_accuracy: 0.9065 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3126 - val_main_out_loss: 1.0053 - val_Ialnslosslayer_loss: 1.5368 - val_main_out_accuracy: 0.6895 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 58/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.9369 - main_out_loss: 0.5966 - Ialnslosslayer_loss: 1.7013 - main_out_accuracy: 0.9101 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3113 - val_main_out_loss: 0.9895 - val_Ialnslosslayer_loss: 1.6090 - val_main_out_accuracy: 0.6935 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 59/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.9203 - main_out_loss: 0.5782 - Ialnslosslayer_loss: 1.7107 - main_out_accuracy: 0.9122 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.3002 - val_main_out_loss: 0.9839 - val_Ialnslosslayer_loss: 1.5819 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 60/75\n",
            "31/31 [==============================] - 5s 157ms/step - loss: 0.9055 - main_out_loss: 0.5633 - Ialnslosslayer_loss: 1.7106 - main_out_accuracy: 0.9213 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.2963 - val_main_out_loss: 0.9837 - val_Ialnslosslayer_loss: 1.5630 - val_main_out_accuracy: 0.7097 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 61/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.8894 - main_out_loss: 0.5456 - Ialnslosslayer_loss: 1.7190 - main_out_accuracy: 0.9244 - Ialnslosslayer_accuracy: 0.0010 - val_loss: 1.2873 - val_main_out_loss: 0.9851 - val_Ialnslosslayer_loss: 1.5107 - val_main_out_accuracy: 0.7056 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 62/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.8746 - main_out_loss: 0.5326 - Ialnslosslayer_loss: 1.7100 - main_out_accuracy: 0.9265 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2851 - val_main_out_loss: 0.9765 - val_Ialnslosslayer_loss: 1.5426 - val_main_out_accuracy: 0.7056 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 63/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.8582 - main_out_loss: 0.5147 - Ialnslosslayer_loss: 1.7173 - main_out_accuracy: 0.9336 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2754 - val_main_out_loss: 0.9661 - val_Ialnslosslayer_loss: 1.5464 - val_main_out_accuracy: 0.7056 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 64/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.8452 - main_out_loss: 0.5048 - Ialnslosslayer_loss: 1.7015 - main_out_accuracy: 0.9362 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2771 - val_main_out_loss: 0.9641 - val_Ialnslosslayer_loss: 1.5653 - val_main_out_accuracy: 0.7097 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 65/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.8315 - main_out_loss: 0.4907 - Ialnslosslayer_loss: 1.7041 - main_out_accuracy: 0.9382 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2650 - val_main_out_loss: 0.9600 - val_Ialnslosslayer_loss: 1.5251 - val_main_out_accuracy: 0.6935 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 66/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.8174 - main_out_loss: 0.4761 - Ialnslosslayer_loss: 1.7065 - main_out_accuracy: 0.9433 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2639 - val_main_out_loss: 0.9578 - val_Ialnslosslayer_loss: 1.5306 - val_main_out_accuracy: 0.7016 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 67/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.8030 - main_out_loss: 0.4613 - Ialnslosslayer_loss: 1.7084 - main_out_accuracy: 0.9464 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2584 - val_main_out_loss: 0.9530 - val_Ialnslosslayer_loss: 1.5271 - val_main_out_accuracy: 0.7056 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 68/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.7918 - main_out_loss: 0.4522 - Ialnslosslayer_loss: 1.6982 - main_out_accuracy: 0.9469 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2520 - val_main_out_loss: 0.9483 - val_Ialnslosslayer_loss: 1.5185 - val_main_out_accuracy: 0.7016 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 69/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.7786 - main_out_loss: 0.4393 - Ialnslosslayer_loss: 1.6967 - main_out_accuracy: 0.9535 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2495 - val_main_out_loss: 0.9430 - val_Ialnslosslayer_loss: 1.5323 - val_main_out_accuracy: 0.7097 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 70/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.7660 - main_out_loss: 0.4258 - Ialnslosslayer_loss: 1.7009 - main_out_accuracy: 0.9591 - Ialnslosslayer_accuracy: 5.1073e-04 - val_loss: 1.2507 - val_main_out_loss: 0.9477 - val_Ialnslosslayer_loss: 1.5149 - val_main_out_accuracy: 0.7016 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 71/75\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.7536 - main_out_loss: 0.4148 - Ialnslosslayer_loss: 1.6941 - main_out_accuracy: 0.9622 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2428 - val_main_out_loss: 0.9460 - val_Ialnslosslayer_loss: 1.4841 - val_main_out_accuracy: 0.6935 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 72/75\n",
            "31/31 [==============================] - 5s 157ms/step - loss: 0.7425 - main_out_loss: 0.4039 - Ialnslosslayer_loss: 1.6931 - main_out_accuracy: 0.9668 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2363 - val_main_out_loss: 0.9433 - val_Ialnslosslayer_loss: 1.4652 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 73/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.7315 - main_out_loss: 0.3964 - Ialnslosslayer_loss: 1.6757 - main_out_accuracy: 0.9709 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2359 - val_main_out_loss: 0.9398 - val_Ialnslosslayer_loss: 1.4808 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 74/75\n",
            "31/31 [==============================] - 5s 157ms/step - loss: 0.7212 - main_out_loss: 0.3848 - Ialnslosslayer_loss: 1.6825 - main_out_accuracy: 0.9699 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2331 - val_main_out_loss: 0.9405 - val_Ialnslosslayer_loss: 1.4627 - val_main_out_accuracy: 0.6935 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Epoch 75/75\n",
            "31/31 [==============================] - 5s 156ms/step - loss: 0.7108 - main_out_loss: 0.3751 - Ialnslosslayer_loss: 1.6788 - main_out_accuracy: 0.9755 - Ialnslosslayer_accuracy: 0.0000e+00 - val_loss: 1.2313 - val_main_out_loss: 0.9339 - val_Ialnslosslayer_loss: 1.4869 - val_main_out_accuracy: 0.6976 - val_Ialnslosslayer_accuracy: 0.0000e+00\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.2035 - main_out_loss: 0.8953 - Ialnslosslayer_loss: 1.5411 - main_out_accuracy: 0.7280 - Ialnslosslayer_accuracy: 0.0000e+00\n",
            "Loss:  [1.2035201787948608, 0.8952913880348206, 1.5411438941955566, 0.7280334830284119, 0.0]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "# ================  Load Data ===================\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "ontime = time.time()\n",
        "\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = getData2()\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "\n",
        "y_train_onehot_labels = np_utils.to_categorical(Y_train, 7)\n",
        "y_test_onehot_lablels = np_utils.to_categorical(Y_test, 7)\n",
        "y_validation_onehot_labels = np_utils.to_categorical(Y_valid, 7)\n",
        "\n",
        "\n",
        "# side loss 的设置为0，是因为我们可以在call的时候会根据分类重新计算\n",
        "# N x 1 为 side loss的维度\n",
        "\n",
        "y_train_origin_centers = np.zeros((len(X_train), 1))\n",
        "y_test_origin_centers = np.zeros((len(X_test), 1))\n",
        "y_valid_origin_centers = np.zeros((len(X_valid), 1))\n",
        "\n",
        "\n",
        "\n",
        "outup = time.time()\n",
        "print('Consumption time', outup - ontime)\n",
        "\n",
        "# ================ Construct Model ===================\n",
        "\n",
        "# model_centerloss = generateModel1()\n",
        "model_centerloss = generateModel2(lambda_c=0.2)\n",
        "\n",
        "\n",
        "\n",
        "# # ================  Model Train & Predict ===================\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 75\n",
        "\n",
        "\n",
        "# 0.65\n",
        "model_centerloss.fit([X_train, y_train_onehot_labels], [y_train_onehot_labels, y_train_origin_centers], batch_size=batch_size,\n",
        "                     epochs = epochs, verbose=1,\n",
        "                     validation_data=([X_valid, y_validation_onehot_labels], [y_validation_onehot_labels, y_valid_origin_centers])\n",
        "                     )\n",
        "Loss = model_centerloss.evaluate([X_test, y_test_onehot_lablels], [y_test_onehot_lablels, y_test_origin_centers], verbose=1)\n",
        "print('Loss: ', Loss)"
      ]
    }
  ]
}